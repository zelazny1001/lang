import os
import re
import openpyxl
import xlsxwriter
import logging
import time

logging.basicConfig(level=logging.DEBUG, format='%(levelname)s:%(message)s')

INPUT_SPREADSHEET = 'J:/projects/sheet-logic/summarization.xlsx'
TARGET_WORKSHEETS = ['sheet2', 'sheet3']
CLUSTER_COL_NAME = 'Clusters'
FLEX = 3
THRESHOLD = 0.2

def clean_token(token):
    return token.strip(".,;:!?")

def find_word_clusters(utterance_str, summary_str, flex, threshold):
    utterance_lower = str(utterance_str).lower()
    summary_lower = str(summary_str).lower()
    target_tokens = [clean_token(token) for token in summary_lower.split()]
    num_target_tokens = len(target_tokens)
    utterance_tokens_lower = [clean_token(token) for token in utterance_lower.split()]
    utterance_tokens_original = utterance_str.split()
    clusters = []
    window_length = max(num_target_tokens, flex)
    normalized_input = " ".join(utterance_str.split())
    def count_ordered_matches(target_tokens, window):
        j = 0
        for token in window:
            if j < len(target_tokens) and token == target_tokens[j]:
                j += 1
            if j == len(target_tokens):
                break
        return j
    for i in range(len(utterance_tokens_lower) - window_length + 1):
        window_lower = utterance_tokens_lower[i:i + window_length]
        window_original = utterance_tokens_original[i:i + window_length]
        matching_count = count_ordered_matches(target_tokens, window_lower)
        if matching_count / num_target_tokens >= threshold:
            clusters.append(" ".join(window_original))
    return merge_clusters(clusters, normalized_input)

def find_max_overlap(a, b):
    max_overlap = 0
    for k in range(1, min(len(a), len(b)) + 1):
        if a[-k:] == b[:k]:
            max_overlap = k
    return max_overlap

def merge_clusters(clusters, normalized_input):
    normalized_input_lower = normalized_input.lower()
    intervals = []
    for cl in clusters:
        cl_lower = cl.lower()
        start = normalized_input_lower.find(cl_lower)
        if start != -1:
            intervals.append((start, start + len(cl_lower)))
    if not intervals:
        return clusters
    intervals.sort(key=lambda x: x[0])
    merged_intervals = [intervals[0]]
    for current in intervals[1:]:
        last = merged_intervals[-1]
        if current[0] <= last[1]:
            merged_intervals[-1] = (last[0], max(last[1], current[1]))
        else:
            merged_intervals.append(current)
    merged_clusters = [normalized_input[s:e] for s, e in merged_intervals]
    return merged_clusters

def highlight_text(text, clusters, normal_format, highlight_format):
    if not clusters:
        return [normal_format, text]
    pattern = re.compile("(" + "|".join(sorted(map(re.escape, clusters), key=len, reverse=True)) + ")", re.IGNORECASE)
    parts = []
    last_index = 0
    for m in pattern.finditer(text):
        start, end = m.start(), m.end()
        if start > last_index:
            parts.extend([normal_format, text[last_index:start]])
        parts.extend([highlight_format, text[start:end]])
        last_index = end
    if last_index < len(text):
        parts.extend([normal_format, text[last_index:]])
    return parts

def highlight_missing_tokens(summary_text, utterance_text, normal_format, missing_format):
    if not summary_text:
        return [normal_format, ""]

    summary_text = str(summary_text)
    utterance_text = str(utterance_text) if utterance_text else ""

    ut_set = {clean_token(token).lower() for token in utterance_text.split()}
    tokens = re.split(r'(\s+)', summary_text)
    parts = []

    for token in tokens:
        if not token or token.isspace():
            parts.extend([normal_format, token])
            continue

        cleaned = clean_token(token).lower()
        if cleaned and cleaned not in ut_set:
            parts.extend([missing_format, token])
        else:
            parts.extend([normal_format, token])

    # Fallback if something went wrong with rich text processing
    if not parts:
        return [normal_format, summary_text]
    return parts

def highlight_summaries(input_spreadsheet, target_worksheet_list):
    CALL_ID_COL_NAME = 'CallId'
    UTTERANCE_COL_NAME = 'UTTERANCE'
    SUMMARY_COL_NAME = 'SUMMARY'
    BRANCH_COL_NAME = 'BRANCH'
    INTENT_COL_NAME = 'INTENT'
    ASSESS_COL_NAME = 'Assess'
    base, ext = os.path.splitext(input_spreadsheet)
    output_spreadsheet = base + "_word_clusters" + ext
    wb_in = openpyxl.load_workbook(input_spreadsheet, data_only=True)
    all_rows = []
    for sheet in wb_in.worksheets:
        rows = list(sheet.iter_rows(values_only=True))
        if not rows:
            continue
        header = rows[0]
        header_indices = {header[i]: i for i in range(len(header))}
        for row in rows[1:]:
            row_data = {
                CALL_ID_COL_NAME: row[header_indices.get(CALL_ID_COL_NAME)],
                UTTERANCE_COL_NAME: row[header_indices.get(UTTERANCE_COL_NAME)],
                SUMMARY_COL_NAME: row[header_indices.get(SUMMARY_COL_NAME)],
                BRANCH_COL_NAME: row[header_indices.get(BRANCH_COL_NAME)],
                INTENT_COL_NAME: row[header_indices.get(INTENT_COL_NAME)],
                ASSESS_COL_NAME: row[header_indices.get(ASSESS_COL_NAME)]
            }
            all_rows.append(row_data)
    wb_out = xlsxwriter.Workbook(output_spreadsheet)
    header_fmt = wb_out.add_format({
        'bold': True,
        'bg_color': '#D7E4BC',
        'align': 'left',
        'valign': 'top',
        'text_wrap': True
    })
    normal_fmt = wb_out.add_format({
        'align': 'left',
        'valign': 'top',
        'text_wrap': True,
        'font_name': 'Calibri',
        'font_size': 9
    })
    highlight_fmt = wb_out.add_format({
        'italic': True,
        'font_color': '#FFA500',
        'align': 'left',
        'valign': 'top',
        'text_wrap': True,
        'font_name': 'Calibri',
        'font_size': 9
    })
    red_fmt = wb_out.add_format({
        'font_color': '#FF0000',
        'align': 'left',
        'valign': 'top',
        'text_wrap': True,
        'font_name': 'Calibri',
        'font_size': 9
    })
    columns = [CALL_ID_COL_NAME, BRANCH_COL_NAME, INTENT_COL_NAME, UTTERANCE_COL_NAME, SUMMARY_COL_NAME, CLUSTER_COL_NAME, ASSESS_COL_NAME]
    col_widths = {
        CALL_ID_COL_NAME: 25,
        BRANCH_COL_NAME: 8,
        INTENT_COL_NAME: 13,
        UTTERANCE_COL_NAME: 60,
        SUMMARY_COL_NAME: 60,
        CLUSTER_COL_NAME: 8,
        ASSESS_COL_NAME: 8
    }
    for target in target_worksheet_list:
        clusters_dict = {}
        filtered_rows = []
        for idx, row in enumerate(all_rows):
            call_id = str(row.get(CALL_ID_COL_NAME, ""))
            if target.lower() in call_id.lower():
                filtered_rows.append(row)
                assess_val = row.get(ASSESS_COL_NAME)
                if assess_val is True or str(assess_val).upper() == "TRUE":
                    utterance_str = row.get(UTTERANCE_COL_NAME, "")
                    summary_str = row.get(SUMMARY_COL_NAME, "")
                    if utterance_str and summary_str:
                        word_clusters = find_word_clusters(utterance_str, summary_str, FLEX, THRESHOLD)
                        logging.debug("Row {}: found {} clusters: {}".format(idx, len(word_clusters), word_clusters))

                        if word_clusters:
                            clusters_dict[len(filtered_rows) - 1] = word_clusters
        ws_out = wb_out.add_worksheet(target)
        for col_idx, col_name in enumerate(columns):
            ws_out.write(0, col_idx, col_name, header_fmt)
            ws_out.set_column(col_idx, col_idx, col_widths[col_name], normal_fmt)
        row_out_idx = 1
        for idx, row in enumerate(filtered_rows):
            ws_out.write(row_out_idx, 0, row.get(CALL_ID_COL_NAME), normal_fmt)
            ws_out.write(row_out_idx, 1, row.get(BRANCH_COL_NAME), normal_fmt)
            ws_out.write(row_out_idx, 2, row.get(INTENT_COL_NAME), normal_fmt)
            utterance_text = str(row.get(UTTERANCE_COL_NAME, "")) if row.get(UTTERANCE_COL_NAME) is not None else ""

            if idx in clusters_dict:
                clusters = clusters_dict[idx]
                rich_parts = highlight_text(utterance_text, clusters, normal_fmt, highlight_fmt)
                ws_out.write_rich_string(row_out_idx, 3, *rich_parts)
            else:
                ws_out.write(row_out_idx, 3, utterance_text, normal_fmt)

            summary_text = str(row.get(SUMMARY_COL_NAME, "")) if row.get(SUMMARY_COL_NAME) is not None else ""
            logging.debug(f"Processing row {idx}, summary text: '{summary_text}'")

            if summary_text:
                red_parts = highlight_missing_tokens(summary_text, utterance_text, normal_fmt, red_fmt)
                logging.debug(f"Summary parts structure: {red_parts}")
                try:
                    ws_out.write_rich_string(row_out_idx, 4, *red_parts)
                except Exception as e:
                    logging.error(f"Failed to write rich string for row {idx}: {e}")
                    ws_out.write(row_out_idx, 4, summary_text, normal_fmt)
            else:
                ws_out.write(row_out_idx, 4, "", normal_fmt)

            cluster_count = len(clusters_dict[idx]) if idx in clusters_dict else 0
            ws_out.write(row_out_idx, 5, cluster_count, normal_fmt)
            ws_out.write(row_out_idx, 6, row.get(ASSESS_COL_NAME), normal_fmt)
            row_out_idx += 1
        ws_out.freeze_panes(1, 0)
        ws_out.autofilter(0, 0, row_out_idx - 1, len(columns) - 1)
    wb_out.close()

if __name__ == '__main__':
    start_time = time.time()
    highlight_summaries(INPUT_SPREADSHEET, TARGET_WORKSHEETS)
    elapsed = time.time() - start_time
    if elapsed >= 60:
        print(f"Elapsed time: {elapsed/60:.2f} minutes")
    else:
        print(f"Elapsed time: {elapsed:.2f} seconds")